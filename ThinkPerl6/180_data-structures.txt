Data Structures

Using Markov analysis to generate random text is fun, but there is also a point to this
exercise: data structure selection. In your solution to the previous exercises, you had
to choose:
• How to represent the prefixes
• How to represent the collection of possible suffixes
• How to represent the mapping from each prefix to the collection of possible suf‐
fixes
The last one is easy: a hash is the obvious choice for a mapping from keys to corre‐
sponding values.
For the prefixes, the most obvious options are a string or a list of strings.
For the suffixes, one option is a list; another is a histogram (hash).

How should you choose? The first step is to think about the operations you will need
to implement for each data structure. For the prefixes, we need to be able to remove
words from the beginning and add words to the end. For example, if the current pre‐
fix is “draw me,” and the next word is “a,” you need to be able to form the next prefix,
“me a,” in order to find the next suffix, “sheep.”
Your first choice might be an array, since it is easy to add and remove elements, but
we also need to be able to use the prefixes as keys in a hash, so that sort of rules out
arrays.

For the collection of suffixes, the operations we need to perform include adding a
new suffix (or increasing the frequency of an existing one), and choosing a random
suffix.
Adding a new suffix is equally easy for the list implementation or the hash. Choosing
a random element from a list is easy; choosing from a hash is harder to do efficiently
(see Exercise 11-6).

So far we have been talking mostly about ease of implementation, but there are other
factors to consider in choosing data structures. One is runtime. Sometimes there is a
theoretical reason to expect one data structure to be faster than other; for example,
we mentioned that a lookup operation is faster for hashes than for arrays, especially
when the number of elements is large.

But often you don’t know ahead of time which implementation will be faster. One
option is to implement both of them and see which is better. This approach is called
benchmarking. A practical alternative is to choose the data structure that is easiest to
implement, and then see if it is fast enough for the intended application. If so, there is
no need to go on. If not, there are tools, like profile modules, that can identify the
places in a program that take the most time.

The other factor to consider is storage space. For example, using a histogram for the
collection of suffixes might take less space because you only have to store each word
once, no matter how many times it appears in the text. In some cases, saving space
can also make your program run faster, and in the extreme, your program might not
run at all if you run out of memory. But for many applications, space is a secondary
consideration after runtime.

One final thought: in this discussion, we have implied that we should use one data
structure for both analysis and generation. But since these are separate phases, it
would also be possible to use one structure for analysis and then convert to another
structure for generation. This would be a net win if the time saved during generation
exceeded the time spent in conversion.

